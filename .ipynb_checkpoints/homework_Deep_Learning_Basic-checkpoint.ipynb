{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c9622b",
   "metadata": {},
   "source": [
    "### Подготовка данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5505f54",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f7e2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for training\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf75c2d",
   "metadata": {},
   "source": [
    "Static configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "364419c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_2_SAMPELS = 'samples/*'\n",
    "TRAIN_DIR = 'data/train'\n",
    "TEST_DIR = 'data/test'\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "ALPHABETH = 'abcdefghijklmnopqrstuvwxyz'\n",
    "DIGITS = '0123456789'\n",
    "CHARS = ALPHABETH + DIGITS\n",
    "VOCAB_SIZE = len(CHARS) + 1\n",
    "\n",
    "lr = 0.01\n",
    "weight_decay = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdbf2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    class for getting data and labels\n",
    "    \"\"\"\n",
    "    def __init__(self, pth):\n",
    "        \"\"\"\n",
    "        collect data\n",
    "        \"\"\"\n",
    "        pth_list = os.listdir(pth)\n",
    "        abs_pth = os.path.abspath(pth)\n",
    "        self.imgs = [os.path.join(abs_pth, p) for p in abs_pth]\n",
    "        self.transform = transforms.Compose([\n",
    "          transforms.ToTensor()  \n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        get length of the data\n",
    "        \"\"\"\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitter__(seld, idx):\n",
    "        \"\"\"\n",
    "        get tensor of the image and label by index\n",
    "        \"\"\"\n",
    "        pth = self.img_list[idx]\n",
    "        label = os.path.basename(pth).split('.')[0].lower()\n",
    "        img = Image.open(pth).convert('RGB')\n",
    "        img_tensor = self.transform(img)\n",
    "        return img_tensor, label\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de5f4239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n"
     ]
    }
   ],
   "source": [
    "# prepare folders\n",
    "os.system(f'mkdir data')\n",
    "os.system(f\"rm -rf data/train\")\n",
    "os.system(f\"rm -rf data/test\")\n",
    "[os.system(f'mkdir data/{directory}') for directory in ('train', 'test')]\n",
    "\n",
    "# split data for train and test 1/4\n",
    "train_set, test_set = train_test_split(glob.glob(PATH_2_SAMPELS), test_size=0.1)\n",
    "train_dataset = CaptchDataset(TRAIN_DIR)\n",
    "val_dataset = CaptchDataset(TEST_DIR)\n",
    "[os.system(f\"cp {te} {VAL_DIR}/{te.split('/')[1]}\") for te in test_set]\n",
    "[os.system(f\"cp {tr} {TRAIN_DIR}/{tr.split('/')[1]}\") for tr in train_set]\n",
    "\n",
    "# loading data\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9a647",
   "metadata": {},
   "source": [
    "### Создание и обучение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b09da3",
   "metadata": {},
   "source": [
    "CRNN class with layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65daea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, dropout=0.5):\n",
    "        \"\"\"\n",
    "        initiate layers\n",
    "        \"\"\"\n",
    "        super(CRNN, self).__init__()\n",
    "        # probability of an element to be zeroed (Bernoulli distribution)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.clayer = nn.Sequential(\n",
    "            # With square kernels and equal stride and with padding\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=32, (3,3),\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            # activation max(0,x)\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(2,2),\n",
    "                stride=2\n",
    "            ),\n",
    "            # in_channels, out_channels, kernel_size\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1, \n",
    "                padding=1),\n",
    "            nn.ReLU(),\n",
    "            # pool of square window of size=2, stride=2\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(2,2), \n",
    "                stride=2\n",
    "            ),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=(3,3), \n",
    "                stride=1, \n",
    "                padding=1\n",
    "            ),\n",
    "            nn.ReLU(), # max(0,x)\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=256, (3,3), \n",
    "                stride=1, \n",
    "                padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(1,2), \n",
    "                stride=2\n",
    "            ),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=256,\n",
    "                out_channels=512,\n",
    "                kernel_size=(3,3), \n",
    "                stride=1, \n",
    "                padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=512,\n",
    "                out_channels=512,\n",
    "                kernel_size=(3,3), \n",
    "                stride=1, \n",
    "                padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(1, 2), \n",
    "                stride=2),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=512,\n",
    "                out_channels=512,\n",
    "                kernel_size=(2,2), \n",
    "                stride=1, \n",
    "                padding=1\n",
    "            ),\n",
    "            self.dropout\n",
    "        )\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=1024, \n",
    "                out_features=256\n",
    "            ),\n",
    "            self.dropout\n",
    "        )\n",
    "        # RNN to an input sequence\n",
    "        self.rnn_layer = nn.GRU(\n",
    "            input_size=256,\n",
    "            hidden_size=256, \n",
    "            num_layers=2, \n",
    "            bidirectional=True\n",
    "        )\n",
    "        # Linear transformation to the incoming data\n",
    "        self.outlayer = nn.Linear(\n",
    "            in_features=512, \n",
    "            out_features=vocab_size\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forvard(self, x):\n",
    "        \"\"\"\n",
    "        method for CNN and RNN combining \n",
    "        \"\"\"\n",
    "        x = self.clayer(x) # CNN apply\n",
    "        x = x.permute(0, 3, 1, 2) # transformate dimension\n",
    "        x = x.view(x.size(0), x.size(1), -1) # choose field\n",
    "        x = self.seq(x) # apply linear with dropout\n",
    "        x, _ = self.rnn_layer(x) # apply rnn layers\n",
    "        x = self.outlayer(x) # apply linear layer\n",
    "        return x.permute(1, 0, 2) # transformate dimension\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881e370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a662b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f609ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
